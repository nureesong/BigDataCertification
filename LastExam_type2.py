''' 
[ë¹…ë°ì´í„°ë¶„ì„ê¸°ì‚¬ ì‹¤ê¸° 2íšŒ ê¸°ì¶œë¬¸ì œ] ìž‘ì—…í˜• ì œ2ìœ í˜•
ë‹¤ìŒì€ ì „ìžìƒê±°ëž˜ ë°°ì†¡ ë°ì´í„°ì´ë‹¤. ðŸ‘‰ðŸ» 10999 observations of 12 variables.
ê³ ê° 10999ëª…ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ì´ìš©í•˜ì—¬ ë¬¼ê±´ì˜ ì •ì‹œ ë„ì°© ì—¬ë¶€(1: No, 0: Yes)ì— ëŒ€í•œ ì˜ˆì¸¡ ëª¨í˜•ì„ ë§Œë“  í›„,
ì´ë¥¼ í‰ê°€ìš© ë°ì´í„°ì— ì ìš©í•˜ì—¬ ì–»ì€ ì œí’ˆì´ âœ¨ì •ì‹œì— ë„ì°©í•  í™•ë¥ âœ¨ì„ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ì˜ csv íŒŒì¼ë¡œ ìƒì„±í•˜ì‹œì˜¤.

ID, Reached.on.Time_Y.N
3500, 0.267
3501, 0.578
3502, 0.885

ðŸš¨ ìœ ì˜ì‚¬í•­
- ì„±ëŠ¥ì´ ìš°ìˆ˜í•œ ì˜ˆì¸¡ëª¨í˜•ì„ êµ¬ì¶•í•˜ê¸° ìœ„í•´ì„œëŠ” ì ì ˆí•œ ë°ì´í„° ì „ì²˜ë¦¬, í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§, ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜, í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹, ëª¨í˜• ì•™ìƒë¸” ë“±ì´ ìˆ˜ë°˜ë˜ì–´ì•¼ í•œë‹¤.
- ì œì¶œí•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì€ ROC-AUC í‰ê°€ì§€í‘œì— ë”°ë¼ ì±„ì í•œë‹¤.
- ìˆ˜í—˜ë²ˆí˜¸.csvíŒŒì¼ì´ ë§Œë“¤ì–´ì§€ë„ë¡ ì½”ë“œë¥¼ ì œì¶œí•œë‹¤.
  pd.DataFrame({'ID': X_test.ID, 'Reached.on.Time_Y.N': pred}).to_csv('0030.csv', index=False)

ðŸ“Œ To Do List
- ì „ì²˜ë¦¬: Label encoding, ì´ìƒì¹˜/ê²°ì¸¡ì¹˜ ì²˜ë¦¬, Normalization
- ëª¨ë¸ë§: XGBoost, SVM, RandomForest, Logistic Regression, MLP
'''

''' Train, Test ë°ì´í„° ë¶„ë¦¬í•˜ê¸°
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split

df = pd.read_csv('/data/Ecommerce_shipping_Train.csv')
X_train, X_test = train_test_split(df, test_size=0.2, random_state=2021)
y_train = X_train[['ID', 'Reached.on.Time_Y.N']]
X_train.drop(columns=['Reached.on.Time_Y.N'], inplace=True)

y_test = X_test[['ID', 'Reached.on.Time_Y.N']]
X_test.drop(columns=['Reached.on.Time_Y.N'],inplace=True)

# Index Re-numbering, ID ì»¬ëŸ¼ì€ ê·¸ëŒ€ë¡œ.
X_train.set_index(keys=np.arange(len(X_train)), inplace=True)
y_train.set_index(keys=np.arange(len(y_train)), inplace=True)
X_test.set_index(keys=np.arange(len(X_test)), inplace=True)

X_train.to_csv('data/Ecommerce_X_train.csv', index=False)
y_train.to_csv('data/Ecommerce_y_train.csv', index=False)
X_test.to_csv('data/Ecommerce_X_test.csv', index=False)
y_test.to_csv('data/Ecommerce_y_test.csv', index=False)
'''

import pandas as pd
X_train = pd.read_csv('data/Ecommerce_X_train.csv')
y_train = pd.read_csv('data/Ecommerce_y_train.csv')
X_test = pd.read_csv('data/Ecommerce_X_test.csv')

y_train = y_train.iloc[:,-1]
assert y_train.ndim == 1  # y_trainì€ 1ì°¨ì› ë°°ì—´ì´ì–´ì•¼ í•œë‹¤.
print('íƒ€ê²Ÿë³€ìˆ˜(ì •ì‹œë„ì°©ì—¬ë¶€) íƒìƒ‰')
print(y_train.value_counts())

# ID ì»¬ëŸ¼ ì œê±°
X_train.drop(columns=['ID'], inplace=True)
X_test_id = X_test['ID']
X_test.drop(columns=['ID'], inplace=True)

# ë²”ì£¼í˜• ë³€ìˆ˜ íƒìƒ‰
categorical = ['Warehouse_block', 'Mode_of_Shipment', 'Product_importance', 'Gender']
for col in categorical:
    print(f'\n{col} ì»¬ëŸ¼ íƒìƒ‰')
    print(X_train[col].value_counts())


# ======  ë°ì´í„° ì „ì²˜ë¦¬ (Lable Encoding)  =======
# Warehouse_block - {A:0, 1:B, 2:C, 3:D, 4:F} / Gender - {F:0, M:1}
# Mode_of_Shipment - {Flight:0, Ship:1, Road:2} / Product_importance - {low:0, medium:1, high:2}

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

X_train[['Warehouse_block','Gender']] = X_train[['Warehouse_block','Gender']].apply(le.fit_transform)
X_test[['Warehouse_block','Gender']] = X_test[['Warehouse_block','Gender']].apply(le.fit_transform)

shipment = {'Flight':0, 'Ship':1, 'Road':2}
X_train['Mode_of_Shipment'] = [shipment[i] for i in X_train['Mode_of_Shipment']]
X_test['Mode_of_Shipment'] = [shipment[i] for i in X_test['Mode_of_Shipment']]

importance = {'low':0, 'medium':1, 'high':2}
X_train['Product_importance'] = [importance[i] for i in X_train['Product_importance']]
X_test['Product_importance'] = [importance[i] for i in X_test['Product_importance']]


# =======  ëª¨ë¸ í•™ìŠµ ë° í‰ê°€  =========
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier

print('\n==== Accuracy ====')
lr = LogisticRegression()
lr.fit(X_train, y_train)
print(f'LR: {round(lr.score(X_train, y_train), 2)}')
pred_lr = lr.predict_proba(X_test)
pred_lr = pred_lr[:,0] # ì •ì‹œì— ë„ì°©(0ìœ¼ë¡œ ì˜ˆì¸¡)í•  í™•ë¥ 


mlp = MLPClassifier(hidden_layer_sizes=(100,),
                    learning_rate_init=1e-4,
                    random_state=42)
mlp.fit(X_train, y_train)
print(f'MLP: {round(mlp.score(X_train, y_train), 2)}')
pred_mlp = mlp.predict_proba(X_test)
pred_mlp = pred_mlp[:,0]


rf = RandomForestClassifier(n_estimators=15,
                            max_depth=3,
                            max_samples=0.2,
                            random_state=42)
rf.fit(X_train, y_train)
print(f'RF: {round(rf.score(X_train, y_train), 2)}')
pred_rf = rf.predict_proba(X_test)
pred_rf = pred_rf[:,0]


knn = KNeighborsClassifier(n_neighbors=5,
                           leaf_size=10)
knn.fit(X_train, y_train)
print(f'KNN: {round(knn.score(X_train, y_train), 2)}')  # overfitting!!
pred_knn = knn.predict_proba(X_test)
pred_knn = pred_knn[:,0]


svc = SVC(probability=True, # ë°˜ë“œì‹œ í•´ì•¼í•¨!
          kernel='rbf',
          random_state=42)
svc.fit(X_train, y_train)
print(f'SVM: {round(svc.score(X_train, y_train), 2)}')  # ë°ì´í„° 10000ê°œ ì´ìƒì´ë©´ ëŠë ¤ì„œ ë¹„íš¨ìœ¨ì 
pred_svc = svc.predict_proba(X_test)
pred_svc = pred_svc[:,0]


xgb = XGBClassifier(n_estimators=100,
                    max_depth=3,
                    use_label_encoder=False,
                    eval_metric='logloss')
xgb.fit(X_train, y_train)
print(f'XGB: {round(xgb.score(X_train, y_train), 2)}')
pred_xgb = xgb.predict_proba(X_test)
pred_xgb = pred_xgb[:,0]

print('\n========  ì˜ˆì¸¡ê²°ê³¼(ì •ì‹œì— ë„ì°©í•  í™•ë¥ ) ë¹„êµ  ========')
output = pd.DataFrame({'ID':X_test_id, 'LR':pred_lr, 'MLP':pred_mlp, 'RF':pred_rf, 'KNN':pred_knn, 'SVM':pred_svc, 'XGB':pred_xgb})
print(output.head(5))

# ì •ë‹µ ì œì¶œ
pred = xgb.predict(X_test)  # xgbì˜ ì„±ëŠ¥ì´ ì œì¼ ì¢‹ë‹¤.
y_pred = pd.DataFrame({'ID':X_test_id, 'Reached.on.Time_Y.N':pred})
# y_pred.to_csv('data/003002225.csv', index=False)


# =======  ì‹¤ì œ ì •ë‹µë¥   =======
import numpy as np
y_test = pd.read_csv('data/Ecommerce_y_test.csv')
acc = np.mean(y_pred['Reached.on.Time_Y.N'].values == y_test['Reached.on.Time_Y.N'].values)
print(f'\n XGB ëª¨ë¸ë¡œ ì˜ˆì¸¡í•œ ê²°ê³¼ >> ì‹¤ì œ ì •ë‹µë¥ : {round(acc,2)}')